p8105_hw2_mff2137
================
Mohammad Fouda

# Load libraries

``` r
library(tidyverse)
library(readxl)
```

# Problem 1

In this step, we import and clean the
`NYC_Transit_Subway_Entrance_And_Exit_Data.csv` dataset starting
withselecting the variables of interest; then change the variables
`route` to character for consistency and replace the value for the
`entry` column from (yes/no) to logical. As it stands, the dataset has
19 columns and 1868 rows. The data is not completely tidy yet. The
`route` columns can be separated into two varibles: route name and route
number changing the dataset from wide to long format.

``` r
nyc_subway <-
    read_csv(
        "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", 
        col_types = c(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
    janitor::clean_names() %>% 
    select(
        line, station_name, station_latitude, station_longitude, 
        starts_with("route"), entrance_type, entry, vending, ada) %>% 
    mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))
```

Since the distinct stations are a combination of both name and line, the
following code chunk will select the disinct stations using the
variables `station_name` and `line`. The resulting number of rows is
equal to the number of distinct stations in the nyc subway system which
is 465.

``` r
nyc_subway %>% 
    select(line, station_name) %>% 
    distinct()
## # A tibble: 465 × 2
##    line     station_name            
##    <chr>    <chr>                   
##  1 4 Avenue 25th St                 
##  2 4 Avenue 36th St                 
##  3 4 Avenue 45th St                 
##  4 4 Avenue 53rd St                 
##  5 4 Avenue 59th St                 
##  6 4 Avenue 77th St                 
##  7 4 Avenue 86th St                 
##  8 4 Avenue 95th St                 
##  9 4 Avenue 9th St                  
## 10 4 Avenue Atlantic Av-Barclays Ctr
## # … with 455 more rows
```

Next code chunk filters out the ADA compliant stations using`ada` column
keeping the `line` and `station_name` and using the `distint()`function
again to find the distinct combinations. The result is 84.

``` r
nyc_subway %>% 
    filter(ada == TRUE) %>% 
    select(line, station_name) %>% 
    distinct()
## # A tibble: 84 × 2
##    line            station_name                  
##    <chr>           <chr>                         
##  1 4 Avenue        Atlantic Av-Barclays Ctr      
##  2 4 Avenue        DeKalb Av                     
##  3 4 Avenue        Pacific St                    
##  4 42nd St Shuttle Grand Central                 
##  5 6 Avenue        34th St                       
##  6 6 Avenue        47-50th Sts Rockefeller Center
##  7 6 Avenue        Church Av                     
##  8 63rd Street     21st St                       
##  9 63rd Street     Lexington Av                  
## 10 63rd Street     Roosevelt Island              
## # … with 74 more rows
```

The following code chunk will calculate the proportion of station
entrances/exists without vending allow entrance. Filtering by `vending`
then using `pull` function with `entry` to coerce the character variable
into numeric. The proportion is 37.7 %.

``` r
nyc_subway %>% 
    filter(vending == "NO") %>% 
    pull(entry) %>% 
    mean
## [1] 0.3770492
```

Finally, we reformat the data so that route number and route name are
distinct variables using `pivot_longer()` then use `distint()` to find
the unique combination of stations serving the A train. The result is 60
stations.

``` r
nyc_subway %>% 
    pivot_longer(
         route1:route11,
        names_to = "route_number",
        values_to = "route_name") %>%
    filter(route_name == "A") %>% 
    select(line, station_name) %>% 
    distinct()
## # A tibble: 60 × 2
##    line            station_name                 
##    <chr>           <chr>                        
##  1 42nd St Shuttle Times Square                 
##  2 8 Avenue        125th St                     
##  3 8 Avenue        145th St                     
##  4 8 Avenue        14th St                      
##  5 8 Avenue        168th St - Washington Heights
##  6 8 Avenue        175th St                     
##  7 8 Avenue        181st St                     
##  8 8 Avenue        190th St                     
##  9 8 Avenue        34th St                      
## 10 8 Avenue        42nd St                      
## # … with 50 more rows
```

This code chunk is similar, adding another filter to find the number of
ADA compliant stations serving the A train. The result is 17 stations.

``` r
nyc_subway %>% 
    pivot_longer(
         route1:route11,
        names_to = "route_number",
        values_to = "route_name") %>%
    filter(route_name == "A" & ada == TRUE) %>% 
    select(line, station_name) %>% 
    distinct()
## # A tibble: 17 × 2
##    line             station_name                 
##    <chr>            <chr>                        
##  1 8 Avenue         14th St                      
##  2 8 Avenue         168th St - Washington Heights
##  3 8 Avenue         175th St                     
##  4 8 Avenue         34th St                      
##  5 8 Avenue         42nd St                      
##  6 8 Avenue         59th St                      
##  7 8 Avenue         Inwood - 207th St            
##  8 8 Avenue         West 4th St                  
##  9 8 Avenue         World Trade Center           
## 10 Broadway         Times Square-42nd St         
## 11 Broadway-7th Ave 59th St-Columbus Circle      
## 12 Broadway-7th Ave Times Square                 
## 13 Canarsie         8th Av                       
## 14 Franklin         Franklin Av                  
## 15 Fulton           Euclid Av                    
## 16 Fulton           Franklin Av                  
## 17 Rockaway         Howard Beach
```

# Problem 2

First code chunk to reading the `Trash Wheel Collecion Data` dataset,
specifying the `Mr. Trash Wheel` sheet. This will also omit the first
row which contains a graphic, the last row which contains the sums, the
last two colums that contains missing data. Additionally, this step
cleans the variable names making it more reasonable to work with and
rounds the number of sports balls to the nearest integer; then converts
the result to an integer variable.

``` r
mr_wheel <- 
    read_excel("data/Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel",
                col_names = TRUE, skip = 1, n_max = 547) %>% 
    janitor::clean_names() %>% 
    select(dumpster:homes_powered) %>% 
    mutate(
        sports_balls = as.integer(ceiling(sports_balls)),
        homes_log = homes_powered > 0,
        ) 
    
```

The next code chunk will use a similar process to import, clean, and
organize the data for the `Professor Trash Wheel` sheet.

``` r
prof_wheel <- 
    read_excel("data/Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel",
                col_names = TRUE, skip = 1, n_max = 94) %>% 
    janitor::clean_names() %>% 
    mutate(
        volume_log = volume_cubic_yards < 15,
        year = as.character(year)
        ) 
```

The following code will combine both `Mr. Trash Wheel` and
`Professor Trash Wheel` datasets to produce a single tidy dataset.

``` r
trash_wheels <- left_join(mr_wheel, prof_wheel)
```

The resulting `Trash Wheels` dataset has 547 observations and
16variables. It includes information on the dumpster number, date of
collection, amount of total litter collected including `weight_tons` and
`volume_cubic_yards`. Some of the litter type variables include
`plastic_bottles`, `cigarette_butts` and `homes_powered` through
incineration of the litter. For available data,
`Professor Trash Wheel`collected 190.12 tons of liter in total. Also
`Mr. Trash Wheel`collected a total of 856sports balls in the year 2020.

# Probelm 3

First code chunks reads in and clean the data in `pols-month.csv`.

``` r
pols<-
    read_csv("data/pols-month.csv") %>% 
    separate(mon, sep = "-", into = c("year", "month", "day")) %>% 
    janitor::clean_names() %>% 
    mutate(across(.col = (c("year", "month")), as.integer)) %>% 
    mutate(
        month = month.abb[month],
        president = case_when(prez_gop == 1 ~ "gop", prez_dem==1 ~ "dem")) %>% 
    select(-day, -prez_gop, -prez_dem)
```

Second code chunk cleans the data in `snp.csv` dataset using a similar
process to the above.

``` r
snp<-
    read_csv("data/snp.csv") %>%
    separate(date, sep = "/",  into = c("month", "day", "year")) %>% 
    mutate(across(.col = (c("year", "month")), as.integer)) %>%
    mutate(
        month = month.abb[month],
        year = if_else(year < 23, 2000 + year, 1900 + year)) %>% 
    select(-day)
    
```

Third code chunk will tidy the `unemployment.csv` data so that it can be
merged with the previous datasets. This requires switching it from
“wide” to “long” format.

``` r
unemployment <-
    read_csv("data/unemployment.csv") %>% 
    janitor::clean_names() %>% 
    pivot_longer(
        jan:dec,
        names_to = "month",
        values_to = "unempl_perc"
    )
```

Next code chunk will join the datasets together to produce one tidy
dataset by merging `snp` into `pols`, and merging `unemployment` into
the result.

``` r
pols_snp <- left_join(pols, snp)
all_data <- left_join(pols_snp, unemployment)
```

The `pols_months` dataset is related to the number of politicians who
are democratic or republican at anytime. The resulting `pols` dataset
has822 observations and 9 variables relating to the period between
1947-2015. Some of the key variables include `president` as `dem` or
`gop`, the `year`, and the number of governors and senators based on
their party affiliation. The `snp` dataset started with 787 observations
and 2 variables with information related to S&P stock market index by
date. The resulting `snp` dataset has 787 observations and 3 variables
representing information on S&P with the key variable of `close` showing
the closing value of S&P at any given `year`in the period 1950-2015. The
`unemployment` dataset started with 68 observations and 13 variables.
The resulting `unemployment` dataset has 816observations and 3 variables
as it was switched from the wide to the long format. It contains
information on the percentages of unemployment `unempl_perc` in any
given `month` in any given `year` in the period 1948-2015. Combined all
3 into one `all_data` final datasets that has 822 observations and 11
variables representing the period 1947-2015.
